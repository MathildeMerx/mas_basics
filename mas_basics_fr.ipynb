{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Multiagent Systems in Python\n",
    "\n",
    "Auteur : Philippe Mathieu, [CRISTAL Lab](https://www.cristal.univ-lille.fr/), [SMAC Team](https://www.cristal.univ-lille.fr/?rubrique26&id=7), [University of Lille](http://www.univ-lille1.fr), email : philippe.mathieu@univ-lille.fr\n",
    "\n",
    "Contributeurs : Nicolas Mauhé (CRISTAL/SMAC)\n",
    "\n",
    "Creation : 18/01/2018\n",
    "\n",
    "\n",
    "## Principe général\n",
    "\n",
    "Les Systèmes multi-agents (SMA) sont des systèmes dans lequel des entités dotées de leur propre comportement, intéragissent entre-elles. Cette approche de modélisation répond à quatre grandes familles de problèmes :\n",
    "- le fait que certains problèmes mettent obligatoirement en oeuvre différentes entités dotées de comportements (c'est le cas des simulateurs sociaux comme les simulateurs de marchés financiers, les simulateurs de trafic routier ou les simulateurs agricoles)\n",
    "- Le fait que à plusieurs, les choses vont plus vite (c'est le cas des applications de type problèmes de patrouilles, de surveillance de bâtiments etc ..)\n",
    "- le fait que les systèmes sont parfois physiquement distribués dans lesquels des logiciels/matériels sur des machines différentes doivent collaborer (résolution de problèmes, applications collaboratives sur smartphones, calculs distribués, reseaux sociaux)\n",
    "- L'étude des systèmes complexes : systèmes avec plusieurs entités qui interagissent, avec en général des boucles de rétro-actions, et dans lesquels des propriétés émergentes apparaissent (turmites, théorie des jeux, etc ...) \n",
    "\n",
    "Il est possible de représenter des agents dans tous les langages, mais\n",
    "les langages objets sont sans aucun doute les plus proches de la\n",
    "philosophie \"Agent\". Un SMA s'écrit donc très facilement à partir d'un\n",
    "langage à objets. Parmi ces langages, Python apporte la concision dans le code. l'objectif de cette page Jupyter n'est pas de fournir un SMA sophistiqué, mais de montrer les bases de sa conception en quelques lignes.\n",
    "\n",
    "## L'agent\n",
    "\n",
    "Dans sa forme la plus simple, un agent est une entité dotée d'une seule\n",
    "capacité, celle de décider quoi faire. Personne ne lui indique ce qu'il doit faire,\n",
    "c'est lui qui décide ! C'est le principe d'**autonomie**. Il suffit juste de lui donner la\n",
    "parole pour qu'il agisse. Lors de sa prise de parole, l'agent réalise sémantiquement 3 étapes différentes : la **perception** de son entourage, la **decision** en fonction de son propre état et de ce qu'il a perçu, puis l'**action** effective qu'il réalise in fine. Idéalement chaque agent ne peut faire qu'une seule action lors de sa prise de parole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "      def __init__(self,name) :\n",
    "          self.name=name\n",
    "        \n",
    "      def decide(self):\n",
    "          print(\"Bonjour ! My name is \"+self.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est bien sûr possible de créer plusieurs agents et de les interroger directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = Agent(\"philippe\")\n",
    "a2 = Agent(\"antoine\")\n",
    "a1.decide()\n",
    "a2.decide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le système multiagent\n",
    "\n",
    "Bien évidemment, un système multi-agent utilise des dizaines voire des\n",
    "milliers d'agents. Il est alors necessaire de créer une classe\n",
    "permettant de les manager. En général la méthode qui lance la\n",
    "simulation se nomme `run` et prend en paramètre le nombre de prises de\n",
    "paroles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class SMA:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.agentList = []\n",
    "        \n",
    "    def addAgent(self,ag):\n",
    "        self.agentList.append(ag)\n",
    "\n",
    "    def run(self,ticks):\n",
    "        for i in range(0,ticks):\n",
    "            random.choice(self.agentList).decide()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma = SMA()\n",
    "sma.addAgent(Agent(\"paul\"))\n",
    "sma.addAgent(Agent(\"kim\"))\n",
    "sma.run(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un système équitable\n",
    "\n",
    "La méthode précédente, triviale,  est discutable. Elle donne au hasard la parole\n",
    "à un agent, et, de ce fait, risque d'en avantager certains. Elle n'est\n",
    "pas équitable. Il est plus judiscieux de s'assurer que chaque agent ait\n",
    "au moins une fois la parole avant qu'un autre agent ne l'ait deux\n",
    "fois. On introduit alors la notion de tour de parole. Chaque tour de\n",
    "parole donne aléatoirement la parole à l'ensemble des agents, avant de\n",
    "recommencer. Un tour de parole constitue sémantiquement une unité de temps, un tick d'horloge. La classe SMA s'écrit alors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class SMA:\n",
    "      def __init__(self):\n",
    "        self.tick=0\n",
    "        self.resetTicks()\n",
    "        self.agentList = []\n",
    "\n",
    "      def resetTicks(self):\n",
    "          tick=0\n",
    "          \n",
    "      def addAgent(self,ag):\n",
    "          self.agentList.append(ag)\n",
    " \n",
    "      def run(self,rounds):\n",
    "          for i in range(0,rounds):\n",
    "              self.runOnce()\n",
    "\n",
    "      def runOnce(self):\n",
    "          self.tick+=1\n",
    "          random.shuffle(self.agentList)\n",
    "          for ag in self.agentList :\n",
    "              ag.decide()\n",
    "          print(\"tick \"+str(self.tick)+\" ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sma = SMA()\n",
    "sma.addAgent(Agent(\"paul\"))\n",
    "sma.addAgent(Agent(\"kim\"))\n",
    "sma.addAgent(Agent(\"Lisa\"))\n",
    "sma.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La vitesse des agents\n",
    "\n",
    "Sur un ordinateur, il n'est jamais possible d'accélérer un processus. Le processus tourne à la vitesse optimale. Néanmoins il est possible de le ralentir. Si on souhaite qu'un agent prenne la parole deux fois moins souvent qu'un autre, il lui suffit alors qu'il la refuse une fois sur deux ce qui se réalise avec un simple modulo dans la procédure de décision. Il est alors possible de paramétrer très finement la vitesse de prise de parole de chaque agent et d'obtenir les rapports de vitesses que l'on souhaite entre les agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "      def __init__(self,name,slowdown) : \n",
    "            self.name=name\n",
    "            self.slowdown=slowdown\n",
    "            self.talk=0\n",
    "            \n",
    "      def decide(self) :\n",
    "            if (sma.tick % self.slowdown != 0):\n",
    "                return\n",
    "            self.talk+=1\n",
    "            print(\"Hello. My name is \"+self.name+\", and this is my \"+str(self.talk)+\" talk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma = SMA()\n",
    "sma.addAgent(Agent(\"paul\",1))\n",
    "sma.addAgent(Agent(\"kim\",2))\n",
    "sma.addAgent(Agent(\"lisa\",3))\n",
    "sma.run(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etudier l'émergence\n",
    "Comme tout outil informatique, le Système Multi Agent (SMA) doit permettre à l'utisateur d'étudier différentes propriétés. Ces propriétés à étudier peuvent être placées au niveau microscopique (c'est  dire au niveau d'un agent, par exemple l'évolution de son bien-être, de sa richesse, de son age ou de sa santé), et/ou au niveau macroscopique (c'est à dire au niveau du SMA comme le nombre d'agents vivants, le chiffre d'affaire d'un magasin, ou le nombre global de messages échangés). Bien sûr, cette observation peut se faire in fine, auquel cas une valeur est renvoyée en fin d'expérience, ou tout au long de l'expérience, amenant alors à des courbes temporelles. \n",
    "\n",
    "Prenons l'exemple d'agents placés dans un reseau social. Chaque agent possède une liste d'accointances (entre 1 et le nombre total d'agents), formant ainsi un graphe social. A des fins d'expériences, une information (`ball`) est passée d'agent en agent (`has_it`), chacun passant l'information à l'une de ses accointances.\n",
    "\n",
    "#### Tout d'abord réalisons le SMA et l'agent ... \n",
    "- Cette fois, c'est le SMA qui crée les agents, dans son constructeur.\n",
    "- Le SMA aura lors de sa construction le nombre d'agents à créer et une matrice d'adjacence de la taille du nombre d'agents : `SMA(10,matrix)`. lors de cette construction le SMA crée les n agents souhaités en leur passant à tous leur identifiant, ainsi que la liste de leurs accointances\n",
    "        for i in range(nb_agents):\n",
    "            self.agentList.append(Agent(i, np.nonzero(adjacency_matrix[i])[0]))\n",
    "- Un agent aura lors de sa construction son identifiant et sa liste d'accointances : `agent(3,[1,5,7])`\n",
    "\n",
    "Cette matrice sera créée en externe par l'une des méthodes du package **numpy** bien adapté à cela. Numpy offre notamment de très nombreuses fonctions de manipulation de matrices. [http://www.numpy.org/] click tutorial to have a brief intro.\n",
    "\n",
    "Dans sa méthode de décision, l'agent regarde s'il a l'information, et si oui, choisit aléatoirement l'un de ses amis dans sa liste pour lui passer.\n",
    "A des fins d'analyse, chaque agent gère aussi son historique des récupérations de la balle : une simple map qui contient à chaque tick le nombre de fois où il a obtenu la balle : {0:0, 1:0, 2:0, 3:1, 4:1, 5:2, 6:2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SMA:\n",
    "    def __init__(self, nb_agents, adjacency_matrix):\n",
    "        self.tick = 0\n",
    "        self.agentList = []\n",
    "        \n",
    "        # Initialize accointances based on the matrix\n",
    "        for i in range(nb_agents):\n",
    "            self.agentList.append(Agent(i, np.nonzero(adjacency_matrix[i])[0]))\n",
    "            \n",
    "    def run(self, rounds):\n",
    "        for i in range(0,rounds):\n",
    "            self.runOnce()\n",
    "\n",
    "    def runOnce(self):\n",
    "        self.tick += 1\n",
    "        for agent in self.agentList:\n",
    "            agent.decide(self.tick)\n",
    "        print(\"tick \" + str(self.tick) + \" ended\")\n",
    "           \n",
    "class Agent:\n",
    "    def __init__(self, id_number, accointances) : \n",
    "        self.id_number = id_number\n",
    "        self.accointances = accointances\n",
    "        self.has_it = False\n",
    "        self.history = {0: 0}\n",
    "            \n",
    "    def decide(self, tick) :\n",
    "        # print(\"agent \"+str(self.id_number)+\" has the talk\")\n",
    "        if tick not in self.history:\n",
    "            self.history[tick] = self.history[tick-1]\n",
    "        if self.has_it:\n",
    "            chosen = np.random.choice(self.accointances, 1)\n",
    "            self.has_it = False\n",
    "            sma.agentList[chosen[0]].has_it = ball\n",
    "            sma.agentList[chosen[0]].history[tick] = sma.agentList[chosen[0]].history[tick-1] + 1\n",
    "            print(str(self.id_number) + \" gives it to \" + str(chosen[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On initialise le système en créant tout d'abord un graphe.\n",
    "Le package **networkx** regorge de méthodes de création de graphes (on s'assure qu'il soit connexe pour que chaque agent ait au moins une accointance). Il suffit ensuite de les convertir en matrices **numpy** pour les passer au SMA.\n",
    "Voir [https://networkx.github.io/] click doc to have many examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nb_agents = 16\n",
    "graph = nx.barabasi_albert_graph(nb_agents, 2)\n",
    "#graph = nx.complete_graph(nb_agents)\n",
    "#graph = nx.erdos_renyi_graph(nb_agents,0.1)\n",
    "#graph = nx.cycle_graph(nb_agents)\n",
    "#graph = nx.random_regular_graph(3,nb_agents)\n",
    "matrix = nx.to_numpy_array(graph, nodelist=range(nb_agents))\n",
    "sma = SMA(nb_agents, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dessin du  graphe social\n",
    "\n",
    "La librairie `matplotlib` facilite grandement les représentations graphiques 2D avec sa fonction`plot`.\n",
    "Plus plus de détails, voir [https://matplotlib.org/users/history.html]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))    # pour définir la taille de la figure\n",
    "nx.draw_networkx(graph)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogramme des degrés du graphe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(dict(graph.degree()).values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution du SMA\n",
    "\n",
    "On donne la balle à un agent au hasard et on lance un certain nombre de tours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On donne la balle\n",
    "ball = \"Could be anything.\"\n",
    "an_agent = np.random.choice(sma.agentList)\n",
    "an_agent.has_it = ball\n",
    "print(\"Initially, agent \"+str(an_agent.id_number)+\" has the ball.\")\n",
    "an_agent.history[0] = 1\n",
    "\n",
    "# On lance le jeu\n",
    "nb_rounds = 40\n",
    "sma.run(nb_rounds)\n",
    "\n",
    "# On reprend la balle, pour une éventuelle réexécution.\n",
    "for agent in sma.agentList:\n",
    "    if agent.has_it:\n",
    "        agent.has_it = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution temporelle du nombre de pastilles par agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenons l'exemple de l'agent 8. On trace l'évolution du nombre de pastilles que cet agent a reçu tout au long de l'expérience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(sorted(list(sma.agentList[8].history.values())))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est d'ailleurs possible d'afficher l'évolution de tous les agents sur le meme graphe (même si avec beaucoup d'agents cela devient vite illisible) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "for agent in sma.agentList:\n",
    "     plt.plot(sorted(list(agent.history.values())), label=agent.id_number)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut également placer des poids sur les noeuds du graphe, liés par exemple au nombre de fois qu'ils ont eu la pastille, puis afficher le graphe avec des intensité de bleus différentes selon ces poids. Cela permet par exemple de vérifier l'hypothèse selon laquelle les agents les plus connectés ont eu plus souvent la pastille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "weights = [agent.history[nb_rounds] for agent in sma.agentList]\n",
    "nx.draw_networkx(graph, node_color=weights, cmap=plt.cm.Blues)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflexions sur la méthode `decide`\n",
    "\n",
    "On peut se demander qui contrôle le fait que chaque agent n'effectue qu'une seule action à chaque tick ? Dans cette implémentation : rien ! Un agent peut parfaitement exécuter plusieurs actions durant une prise parole sans que le système n'en sache rien.  En pratique, lors de la conception d'un SMA, deux possibilités s'offrent au développeur pour la gestion de la méthode decide :\n",
    "1. soit on considère que le SMA n'est qu'un \"scheduling system\", et qu'il donne uniquement le controle aux agents comme le ferait le système d'exploitation avec des Threads. La methode `decide` exécute les actions et ne renvoie alors rien. De ce fait les agents peuvent éventuellement faire plusieurs actions, mais en contrepartie on respecte strictement le **principe d'autonomie**\n",
    "2. Soit on considère que l'on s'autorise des actions dans le SMA. La méthode décide devient une fonction qui renvoie l'action à effectuer et c'est le SMA lui même qui l'exécute. Il est de ce fait possible de contrôler les agents, mais l'agent n'est plus vraiment autonome.\n",
    "\n",
    "Controle des agents ou autonomie des agents, il faut choisir !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercices\n",
    "\n",
    "## Exercice 1\n",
    "Cette application permet de lancer plusieurs balles simultanément. Modifiez l'application pour qu'elle s'arrête quand un des agents réussit à avoir deux balles en même temps. Le système affichera alors le nombre d'étapes nécessaires pour parvenir à cette situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2\n",
    "\n",
    "En s'appuyant sur l'exercice 1, créez une méthode permettant pour un type de réseau de réaliser `n` expériences consécutives. Les valeurs de `n` et du réseau seront passés en paramètre. La méthode renverra le nombre d'étapes moyen qu'il a fallu réaliser pour arriver à l'arrêt (un agent avec 2 balles).\n",
    "\n",
    "Testez cette méthode avec 4 types de réseaux différents (`nx.complete_graph(nb_agents)`, `nx.erdos_renyi_graph(nb_agents,0.1)`,`nx.cycle_graph(nb_agents)`,`nx.random_regular_graph(3,nb_agents)`) et montrez l'influence du réseau sur le nombre d'étapes nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3\n",
    "Sur le même principe que précédemment, on souhaite réaliser un système dans lequel tous les agents se connaissent, et chaque agent possède un certain nombre d'unités de richesse (`wealth`). Initalement, tous sont parfaitement égaux et ont tous une richesse de 5. Chaque fois qu'un agent a la parole (donnée de manière équitable), l'agent choisit au hasard un autre agent et lui donne 1 richesse (s'il n'est pas à 0 bien sûr). Réalisez `n` tours de parole et tracez ensuite un diagramme de type `bar` indiquant la richesse par agent, ainsi que l'histogramme de distribution des richesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 4\n",
    "On souhaite maintenant que les agents aient une préférence pour leur classe sociale, donc ici pour les agents qui ont grosso-modo la même richesse qu'eux. Cette fois la richesse est tirée uniformément entre 1 et 10. Faites en sorte que les dons soient toujours faits avec un agent pris aléatoirement, mais cette fois ci, avec une probabilité proportionnelle à l'inverse de l'écart à son propre wealth. Dans le cas où l'écart est nul (ce qui impliquerait une division par zéro), on pourra fixer la probabilité à 2 (ils ont alors plus de chances d'être pris quand ils sont égaux, que quand ils ont 1 de différence). Retestez ensuite l'évolution de l'histogramme des richesses.\n",
    "\n",
    "\n",
    "\n",
    "*Aide: Il s'agit ici de programmer une sorte de \"roue de la fortune\" (pour info la methode `Choice` de `numpy` permet d'indiquer des distributions de probas) dans le processus de décision de l'agent : au moment de sa décision, l'agent calcule une map avec comme clé l'un des agents et comme valeur l'inverse de l'écart à son propre wealth. Il fait ensuite la somme totale des valeurs obtenues et tire un nombre aléatoire entre 0 et ce total. Il reparcourt son tableau en cumulant les valeurs à concurrence du nombre tiré. L'agent sur lequel il tombe correspond à celui à qui il fait un don.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliographie\n",
    "\n",
    "Philippe Mathieu, Yann Secq.\n",
    "Environment Updating and Agent Scheduling Policies in Agent-based Simulators. \n",
    "ICAART Conference, 2012, pp 170-175\n",
    "\n",
    "Philippe Mathieu, Sébastien Picault, Yann Secq.\n",
    "Design Patterns for Environments in Multi-agent Simulations. \n",
    "PRIMA Conference, 2015, pp 678-686\n",
    "\n",
    "Philippe Mathieu, Gildas Morvan, Sébastien Picault.\n",
    "Multi-level agent-based simulations: Four design patterns. \n",
    "Journal of Simulation Modelling Practice and Theory, Janv 2018\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
